{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46a39c5-7749-4ab1-8144-4ffc15f7ad93",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Purpose\n",
    "generate virtual detector images with single Bragg spots. This notebook will generate images of rystals with each radius."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad066f7-dc66-4343-839f-ac22e13c0352",
   "metadata": {},
   "source": [
    "## setup modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71acf2db-f150-4c5a-b93b-999c52ac0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import os\n",
    "import time\n",
    "from typing import Tuple, Union, Dict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7048c6ef-b10e-4e9a-ae9c-b13eaf6b613a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370e4e3b-f377-464b-8cd7-0819d596a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_h5_tree(val, pre=''):\n",
    "    if isinstance(val, h5py._hl.files.File):\n",
    "        print(val.filename)\n",
    "\n",
    "    items = len(val)\n",
    "    for key, val in val.items():\n",
    "        items -= 1\n",
    "        if items == 0:\n",
    "            # the last item\n",
    "            if isinstance(val, h5py._hl.group.Group):\n",
    "                print(pre + '└── ' + key)\n",
    "                print_h5_tree(val, pre+'    ')\n",
    "            else:\n",
    "                print(pre + '└── ' + key)\n",
    "        else:\n",
    "            if isinstance(val, h5py._hl.group.Group):\n",
    "                print(pre + '├── ' + key)\n",
    "                print_h5_tree(val, pre+'│   ')\n",
    "            else:\n",
    "                print(pre + '├── ' + key)\n",
    "\n",
    "\n",
    "def print_h5_tree_from_path(fpath: str):\n",
    "    with h5py.File(fpath, \"r\") as tree:\n",
    "        print_h5_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b955b0ee-1b69-46c3-b1a0-cda1c353bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fourier_modulus(fpath: str) -> np.ndarray:\n",
    "    dst = None\n",
    "    with h5py.File(fpath, \"r\") as tree:\n",
    "        dst = tree['outputs']['main_outputs']['fourier_modulus'][()]\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0a8e1d-e3cf-4222-bc11-83d95dbbf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qrange(fpath: str) -> Tuple[Union[Dict[str, Union[Tuple[float], float]], float]]:\n",
    "    qranges = {\n",
    "        'x': None,  # (min, max)\n",
    "        'y': None,  # (min, max)\n",
    "    }\n",
    "    dqs = {\n",
    "        'x': None,\n",
    "        'y': None,\n",
    "    }\n",
    "    q_spot_expected = None\n",
    "    with h5py.File(fpath, \"r\") as tree:\n",
    "        qranges['x'] = (\n",
    "            tree['outputs']['momentum_space']['momentum_x'][()].min(),\n",
    "            tree['outputs']['momentum_space']['momentum_x'][()].max()\n",
    "        )\n",
    "        qranges['y'] = (\n",
    "            tree['outputs']['momentum_space']['momentum_y'][()].min(),\n",
    "            tree['outputs']['momentum_space']['momentum_y'][()].max()\n",
    "        ) \n",
    "\n",
    "        dqs['x'] = np.diff(sorted(np.unique(tree['outputs']['momentum_space']['momentum_x'][()])))[0]\n",
    "        dqs['y'] = np.diff(sorted(np.unique(tree['outputs']['momentum_space']['momentum_y'][()])))[0]\n",
    "\n",
    "        q_spot_expected = 2. * np.pi / tree['input_parameters']['target']['unit_cell_length'][()] * \\\n",
    "            np.linalg.norm(tree['input_parameters']['target']['miller_index'][()])\n",
    "    \n",
    "    return qranges, dqs, q_spot_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "598b6e0c-4e9a-4fe9-a784-ed24fb9012e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spot_positions(fpath: str):\n",
    "    pos_spot_ranges = {  # (min, max)\n",
    "        'x': None,\n",
    "        'y': None\n",
    "    }\n",
    "    pos_spot_peak = {\n",
    "        'x': None,\n",
    "        'y': None\n",
    "    }\n",
    "    with h5py.File(fpath, 'r') as tree:\n",
    "        pos_spot_ranges['x'] = tree['outputs']['positions']['pos_spot_range_x'][()]\n",
    "        pos_spot_ranges['y'] = tree['outputs']['positions']['pos_spot_range_y'][()]\n",
    "        pos_spot_peak['x'] = tree['outputs']['positions']['pos_spot_peak_x'][()]\n",
    "        pos_spot_peak['y'] = tree['outputs']['positions']['pos_spot_peak_y'][()]\n",
    "    \n",
    "    return pos_spot_ranges, pos_spot_peak\n",
    "\n",
    "\n",
    "def get_spot_qrange(pos_spot_ranges, pos_spot_peak, dqs, qranges):\n",
    "    pos_spot_qranges = {}\n",
    "    for key in pos_spot_ranges.keys():\n",
    "        pos_spot_qranges[key] = qranges[key][0] + np.arange(pos_spot_ranges[key][0], pos_spot_ranges[key][1] + 1) * dqs[key]\n",
    "\n",
    "    pos_spot_peak_q = {}\n",
    "    for key in pos_spot_peak.keys():\n",
    "        pos_spot_peak_q[key] = qranges[key][0] + pos_spot_peak[key] * dqs[key]\n",
    "    \n",
    "    return pos_spot_qranges, pos_spot_peak_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2497d4bc-bf84-413d-9552-66b699390915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spot_positions(\n",
    "    intensity_map: np.ndarray, mu_r: float,\n",
    "    sigma_r: float, n_shots: int\n",
    "):\n",
    "    r_spot = np.random.normal(mu_r, sigma_r, n_shots)\n",
    "    theta_spot = np.random.uniform(0.0, 2. * np.pi, n_shots)\n",
    "    x = r_spot * np.sin(theta_spot) + intensity_map.shape[1]//2\n",
    "    y = r_spot * np.cos(theta_spot) + intensity_map.shape[0]//2\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17419164-35d1-44c2-adba-8e2233649c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(\n",
    "    intensity_map: np.ndarray, x: int, y: int,\n",
    "    pos_spot_ranges: dict, pos_spot_peak: dict\n",
    ") -> np.ndarray:\n",
    "    image = np.zeros(intensity_map.shape)\n",
    "    shift_x =  x - pos_spot_peak['x']\n",
    "    shift_y =  y - pos_spot_peak['y']\n",
    "    image[\n",
    "        pos_spot_ranges['y'][0] + shift_y:pos_spot_ranges['y'][1] + shift_y + 1,\n",
    "        pos_spot_ranges['x'][0] + shift_x:pos_spot_ranges['x'][1] + shift_x + 1,\n",
    "    ] = intensity_map[\n",
    "        pos_spot_ranges['y'][0]:pos_spot_ranges['y'][1]+1,\n",
    "        pos_spot_ranges['x'][0]:pos_spot_ranges['x'][1]+1\n",
    "    ].copy()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6825c221-36e4-4d23-be4c-93595029ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_params(group, key, values):\n",
    "    if values.get('value') is not None:\n",
    "        _ = group.create_dataset(key, data=values['value'])\n",
    "        return group\n",
    "    group_ = group.create_group(f'{key}')\n",
    "    for key_, values_ in values.items():\n",
    "        group_ = add_params(group_, key_, values_)\n",
    "    return group\n",
    "\n",
    "\n",
    "def output(dstpath: str, parameters: dict, outputs: dict):\n",
    "    with h5py.File(dstpath, 'w') as tree:\n",
    "        # parameters\n",
    "        tree = add_params(tree, 'input_parameters', parameters)\n",
    "\n",
    "        # outputs\n",
    "        tree = add_params(tree, 'outputs', outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd00e5-92b8-4a9d-b4d1-0ad700e4221d",
   "metadata": {},
   "source": [
    "## paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d454ccd8-fd5b-431e-9eeb-b07ad3a6d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src\n",
    "srcdir = \"../output_data/01_simulation/\"\n",
    "srclist = sorted(glob.glob(os.path.join(srcdir, \"*.h5\")))\n",
    "\n",
    "# normalization factor\n",
    "factor_result_path = \"../output_data/02_normalization/factor.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448fe379-4cd5-4f83-8af5-014f000d5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "srclist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cdce61-1cad-4303-bf26-d5603a931112",
   "metadata": {},
   "source": [
    "## load the normalization factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14b3665-8afa-414c-8f1a-82dfcb7ad22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = None\n",
    "with h5py.File(factor_result_path, 'r') as tree:\n",
    "    factor = tree['outputs']['main_outputs']['normalization_factor'][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36defd0-680d-4fd1-a13c-1f13b17feb87",
   "metadata": {},
   "source": [
    "## get the index corresponding to the crystal with the maximum radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38451d72-085c-4c1f-8794-d6c37c69f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "radii = []\n",
    "for fpath in srclist:\n",
    "    with h5py.File(fpath, \"r\") as tree:\n",
    "        radii.append(tree['input_parameters']['target']['crystal_characteristic_length'][()])\n",
    "\n",
    "radii = np.array(radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfbfb7f3-1aae-4a74-8e2e-abb96f01eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_radii_max = np.where(radii == radii.max())[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3f6bd-6f4d-4ac1-9496-3e42db84d96d",
   "metadata": {},
   "source": [
    "## get q-ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "136dbb8b-012c-4935-bc88-054b4b9b0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "qranges, dqs, q_spot_expected = get_qrange(srclist[ind_radii_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b6536-3d0f-4a4b-88bf-51f4dc5558eb",
   "metadata": {},
   "source": [
    "## load spot positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ebb9cfa-f6d1-446f-84ea-150856eb6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_spot_ranges, pos_spot_peak = load_spot_positions(factor_result_path)\n",
    "pos_spot_qranges, pos_spot_peak_q = get_spot_qrange(\n",
    "    pos_spot_ranges, pos_spot_peak, dqs, qranges\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d79d6b-6003-436a-8e81-6cad3f7d6e4a",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c242614-3b29-43ac-a75f-82c6d05a18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_format = {\n",
    "    'source': {\n",
    "        'srcpath': {\n",
    "            'value': None,\n",
    "            'unit': 'none',\n",
    "            'type': 'str'\n",
    "        },\n",
    "        'factor_result_path': {\n",
    "            'value': factor_result_path,\n",
    "            'unit': 'none',\n",
    "            'type': 'str'\n",
    "        }\n",
    "    },\n",
    "    'random_seed': {\n",
    "        'value': None,\n",
    "        'unit': 'none',\n",
    "        'type': 'int'\n",
    "    },\n",
    "    'image': {\n",
    "        'number_of_images': {\n",
    "            'value': 100,\n",
    "            'unit': 'none',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        'radius_std': {\n",
    "            'value': 2.0,\n",
    "            'unit': 'pixel',\n",
    "            'type': 'float'\n",
    "        }\n",
    "    },\n",
    "    'detector_noise': {\n",
    "        'mean': {\n",
    "            'value': 0.0,\n",
    "            'unit': 'photons',\n",
    "            'type': 'float'\n",
    "        },\n",
    "        'std': {\n",
    "            'value': 0.1,\n",
    "            'unit': 'photons',\n",
    "            'type': 'float'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fcc67a6-3520-4fc0-aa25-28b21a23cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_format = {\n",
    "    'main_outputs': {\n",
    "        'images': {\n",
    "            'value': None,\n",
    "            'unit': 'photons',\n",
    "            'type': 'numpy.ndarray(float)'\n",
    "        }\n",
    "    },\n",
    "    'expected_positions': {\n",
    "        'x': {\n",
    "            'value': None,\n",
    "            'unit': 'pixel',\n",
    "            'type': 'tuple(float)'\n",
    "        },\n",
    "        'y': {\n",
    "            'value': None,\n",
    "            'unit': 'pixel',\n",
    "            'type': 'tuple(float)'\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39b1fa89-981b-4c07-85d0-38c5b659fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'images_R{0:.2f}A_{1}shots.h5'\n",
    "outputdir = '../output_data/03_calculate_exp_data'\n",
    "\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55914edd-bd10-44b1-be54-f00219507032",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54a1f5dd-3a8a-45c7-b119-6a256f1b81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_start = 1023\n",
    "seed_step = 10\n",
    "\n",
    "seeds = np.arange(seed_start, seed_start + seed_step * len(srclist), seed_step).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c16af9-38a1-4d45-8f72-62437500e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "for ii, fpath in enumerate(srclist):\n",
    "    print(\"target:\", fpath)\n",
    "    # update parameters\n",
    "    parameters = copy.deepcopy(parameters_format)\n",
    "    parameters['source']['srcpath']['value'] = fpath\n",
    "    parameters['random_seed']['value'] = seeds[ii]\n",
    "    \n",
    "    # get parameters\n",
    "    sigma_r = parameters['image']['radius_std']['value']\n",
    "    n_shots = parameters['image']['number_of_images']['value']\n",
    "    mu_bg = parameters['detector_noise']['mean']['value']\n",
    "    sigma_bg = parameters['detector_noise']['std']['value']\n",
    "    \n",
    "    # load the intensity map and execute normalization\n",
    "    intensity = get_fourier_modulus(fpath)\n",
    "    intensity = factor * np.abs(intensity)**2\n",
    "    mu_r = ((pos_spot_peak['x'] - intensity.shape[1]//2)**2 + \\\n",
    "    (pos_spot_peak['y'] - intensity.shape[0]//2)**2)**0.5\n",
    "    \n",
    "    # generate spot positions\n",
    "    np.random.seed(seeds[ii])\n",
    "    x, y = generate_spot_positions(intensity, mu_r, sigma_r, n_shots)\n",
    "    \n",
    "    # generate images\n",
    "    images = np.zeros((n_shots, intensity.shape[0], intensity.shape[1]))\n",
    "    for ii in range(n_shots):\n",
    "        image_ = generate_image(\n",
    "            intensity, int(x[ii]), int(y[ii]),\n",
    "            pos_spot_ranges, pos_spot_peak\n",
    "        )\n",
    "\n",
    "        # add noise\n",
    "        images[ii] = np.random.poisson(image_).astype(np.float64) + np.random.normal(mu_bg, sigma_bg, image_.shape)\n",
    "    \n",
    "    # set the output path\n",
    "    raduis_ = None\n",
    "    with h5py.File(fpath, \"r\") as tree:\n",
    "        radius_ = tree['input_parameters']['target']['crystal_characteristic_length'][()]\n",
    "    dstpath = os.path.join(outputdir, fname.format(radius_, n_shots))\n",
    "\n",
    "    # output the results\n",
    "    outputs = copy.deepcopy(outputs_format)\n",
    "    outputs['main_outputs']['images']['value'] = images\n",
    "    outputs['expected_positions']['x']['value'] = x\n",
    "    outputs['expected_positions']['y']['value'] = y\n",
    "    output(dstpath, parameters, outputs)\n",
    "    print(f\"elapsed time: {time.time() - st:.2f} sec.\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a36943e-fcb4-40cf-872d-ff4ca6c471e5",
   "metadata": {},
   "source": [
    "## chech the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265efeaf-b5eb-4ca3-aa9a-3d1727b62050",
   "metadata": {},
   "outputs": [],
   "source": [
    "dstlist = sorted(glob.glob(os.path.join(outputdir, \"*.h5\")))\n",
    "\n",
    "len(dstlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304950b5-99b1-4b10-9f6a-cbc222f5cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_h5_tree_from_path(dstlist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f207b02-8e8d-410a-8c82-53274bb5e15d",
   "metadata": {},
   "source": [
    "### plot the summed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba77cdea-d217-4a3f-b18f-b82cd34032e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir_img = '../output_data/03_calculate_exp_data_img'\n",
    "\n",
    "if not os.path.exists(outputdir_img):\n",
    "    os.makedirs(outputdir_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f118a6fd-1e5b-4976-9058-987f17a7ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = [\n",
    "    qranges['x'][0] - dqs['x'] / 2.0, qranges['x'][1] + dqs['x'] / 2.0,\n",
    "    qranges['y'][0] - dqs['y'] / 2.0, qranges['y'][1] + dqs['y'] / 2.0\n",
    "]  # (left, right, bottom, top)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "for fpath in dstlist:\n",
    "    fname = os.path.basename(fpath)\n",
    "    image = None\n",
    "    with h5py.File(fpath, 'r') as tree:\n",
    "        images_ = tree['outputs']['main_outputs']['images'][()]\n",
    "        image = images_.sum(axis=0)\n",
    "\n",
    "    # show the modulus\n",
    "    plt.clf()\n",
    "    plt.subplot(111)\n",
    "    plt.imshow(\n",
    "        image, origin='lower', extent=extent,\n",
    "        norm=LogNorm(vmin=image.max() / 1e2, vmax=image.max())\n",
    "    )\n",
    "\n",
    "    # plot a circle with a radius of $2\\pi / d(111)$\n",
    "    theta = np.arange(0., 2.*np.pi, np.pi/100)\n",
    "    plt.plot(q_spot_expected * np.sin(theta), q_spot_expected * np.cos(theta), '-')\n",
    "\n",
    "    # plot a peak position and cross lines at the peak\n",
    "    plt.plot(pos_spot_peak_q['x'], pos_spot_peak_q['y'], \"o\")\n",
    "    plt.hlines(\n",
    "        pos_spot_peak_q['y'], pos_spot_qranges['x'][0], pos_spot_qranges['x'][-1],\n",
    "        colors='y'\n",
    "    )\n",
    "    plt.vlines(\n",
    "        pos_spot_peak_q['x'], pos_spot_qranges['y'][0], pos_spot_qranges['y'][-1],\n",
    "        colors='y'\n",
    "    )\n",
    "\n",
    "    plt.xlabel('$q_x (1/\\AA$)')\n",
    "    plt.ylabel('$q_y (1/\\AA$)')\n",
    "    plt.title(f'sum of images in {fname}')\n",
    "\n",
    "    # plt.xlim(pos_spot_qranges['x'][0], pos_spot_qranges['x'][-1])\n",
    "    # plt.ylim(pos_spot_qranges['y'][0], pos_spot_qranges['y'][-1])\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(outputdir_img, fname.replace('h5', 'png')),\n",
    "        bbox_inches='tight', pad_inches=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3ab46-ef77-4f46-a101-7c8ca6505eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dg_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
